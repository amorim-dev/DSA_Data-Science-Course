{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ce2f19",
   "metadata": {},
   "source": [
    "# Big Data Real-Time Analytics with Python and Spark\n",
    "\n",
    "## Chapter 2  - Case Study 1 - Cleaning and processing data with Numpy\n",
    "\n",
    "- Documentation: https://numpy.org/\n",
    "- Data from: https://www.openintro.org/data/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735548d",
   "metadata": {},
   "source": [
    "![Case Study DSA](images/CaseStudy1.png \"Case Study DSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0e6b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version used in this notebook is:  3.8.8\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "from platform import python_version\n",
    "print('The version used in this notebook is: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a62d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the only library for the Python that we will use here \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7940c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca43be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Bianca Amorim\n",
      "\n",
      "numpy: 1.20.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# package version used in this notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Bianca Amorim\" --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939698d0",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54422aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print setting in Numpy\n",
    "np.set_printoptions(suppress = True, linewidth = 200, precision = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafdc64",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fd1dd",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data set \n",
    "dataset = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                        delimiter = \";\",\n",
    "                        skip_header = 1,\n",
    "                        autostrip = True,\n",
    "                        encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a438464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking type (ndarray is an array with many dimensions)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5517bebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 lines for 14 columns\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8e3b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab7da7",
   "metadata": {},
   "source": [
    "**\"nan\"** means \"not a number\". But we don't have empty columns. what happened was numpy did not recognize some data. This is because the special characters in the data set and the way NumPy loads numerical and string data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9a30a",
   "metadata": {},
   "source": [
    "## Verificando Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b45afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of total missing values\n",
    "# A good part of these missing values were generated at the time we loaded the data\n",
    "np.isnan(dataset).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a677f9",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.nanmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378e8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68616520.0\n"
     ]
    }
   ],
   "source": [
    "# It will return the highest value + 1, ignoring nan values\n",
    "# We will use this to fill in the nan values at the moment of the loading data numerical variables\n",
    "# then we will trear this value as a missing value\n",
    "joker_value = np.nanmax(dataset) + 1\n",
    "print(joker_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c922ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If I do not use this function above to ignore nan, the max values will be nan\n",
    "np.max(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577804b",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2394afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54015809.19         nan    15273.46         nan    15311.04         nan       16.62      440.92         nan         nan         nan         nan         nan     3143.85]\n"
     ]
    }
   ],
   "source": [
    "# We calculate the average of the numerical variables ignoring the nan values in the column\n",
    "# We will use this to separate numerical variables from string variables\n",
    "average_ignoring_nan = np.nanmean(dataset, axis = 0)\n",
    "print(average_ignoring_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9460163",
   "metadata": {},
   "source": [
    "- Return the position of the elements, that are non-zero\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98798815",
   "metadata": {},
   "source": [
    "- Squeeze the array, because we don't need [[0,1], [0, 3] ...\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f27dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with data type string with nan values\n",
    "# squeeze() We tranforming multiples arrays in one\n",
    "string_columns = np.argwhere(np.isnan(average_ignoring_nan)).squeeze()\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c7919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False,  True, False, False,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The function argwhere above return the position only if is true(1)\n",
    "# Because the false is a 0, and the function argwhere do not return position when the value is a 0\n",
    "np.isnan(average_ignoring_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f60b2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see filter numerical columns\n",
    "numerical_columns = np.argwhere(np.isnan(average_ignoring_nan) == False).squeeze()\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe8a3625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True, False,  True,  True, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the columns which is true is the not nan\n",
    "np.isnan(average_ignoring_nan) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885f4b0",
   "metadata": {},
   "source": [
    "> Import the dataset again, separating string columns from numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d202b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will loading only the columns with string data type \n",
    "# We specify the string columns with the index and their data type\n",
    "arr_strings = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                           delimiter = \";\",\n",
    "                           skip_header = 1,\n",
    "                           autostrip = True,\n",
    "                           usecols = string_columns,\n",
    "                           dtype = str,\n",
    "                           encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f9053bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da9aabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will loading only the columns with numerical data type \n",
    "# We specify the numerical columns with the index and their data type\n",
    "# filling_values - set values to be used as default when the data are missing.\n",
    "arr_numeric = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                           delimiter = \";\",\n",
    "                           skip_header = 1,\n",
    "                           autostrip = True,\n",
    "                           usecols = numerical_columns,\n",
    "                           filling_values = joker_value,\n",
    "                           encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cbf45e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d37879",
   "metadata": {},
   "source": [
    "> Now we are going to extract the columns names, we didn't extract them before because they are all of type string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19fd6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the columns name\n",
    "arr_columns_name = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                                delimiter = \";\",\n",
    "                                autostrip = True,\n",
    "                                skip_footer = dataset.shape[0],\n",
    "                                dtype = str,\n",
    "                                encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78e508b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_columns_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd21b8",
   "metadata": {},
   "source": [
    "> \"skip_footer\" is the number of lines to skip at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50cf8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and string column headers\n",
    "header_strings, header_numerical = arr_columns_name[string_columns], arr_columns_name[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31d642fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd11f33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766f573",
   "metadata": {},
   "source": [
    "## Checkpoint function\n",
    "#### Checkpoint 1\n",
    "We will create a checkpoint function to salve the intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4283319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_columns_name\t arr_numeric\t arr_strings\t average_ignoring_nan\t dataset\t header_numerical\t header_strings\t joker_value\t np\t \n",
      "numerical_columns\t python_version\t string_columns\t warnings\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6af2c673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_columns_name\t arr_numeric\t arr_strings\t average_ignoring_nan\t dataset\t header_numerical\t header_strings\t numerical_columns\t string_columns\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%who ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc58b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Python version\n",
      "from platform import python_version\n",
      "print('The version used in this notebook is: ', python_version())\n",
      "# Import the only library for the Python that we will use here \n",
      "import numpy as np\n",
      "# Warning filter\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "# package version used in this notebook\n",
      "%reload_ext watermark\n",
      "%watermark -a \"Bianca Amorim\" --iversion\n",
      "# print setting in Numpy\n",
      "np.set_printoptions(suppress = True, linewidth = 200, precision = 2)\n",
      "# loading the data set \n",
      "dataset = np.genfromtxt(\"datasets/dataset1.csv\",\n",
      "                        delimiter = \";\",\n",
      "                        skip_header = 1,\n",
      "                        autostrip = True,\n",
      "                        encoding = 'cp1252')\n",
      "# Cheking type (ndarray is an array with many dimensions)\n",
      "type(dataset)\n",
      "# 1000 lines for 14 columns\n",
      "dataset.shape\n",
      "dataset.view()\n",
      "np.isnan(dataset).sum()\n",
      "# It will return the highest value + 1, ignoring nan values\n",
      "# We will use this to fill in the nan values at the moment of the loading data numerical variables\n",
      "# then we will trear this value as a missing value\n",
      "joker_value = np.nanmax(dataset) + 1\n",
      "print(joker_value)\n",
      "np.max(dataset)\n",
      "# It will return the highest value + 1, ignoring nan values\n",
      "# We will use this to fill in the nan values at the moment of the loading data numerical variables\n",
      "# then we will trear this value as a missing value\n",
      "joker_value = np.nanmax(dataset) + 1\n",
      "print(joker_value)\n",
      "#If I do not use this function above to ignore nan, the max values will be nan\n",
      "np.max(dataset)\n",
      "# We calculate the average of the numerical variables ignoring the nan values in the column\n",
      "# We will use this to separate numerical variables from string variables\n",
      "average_ignoring_nan = np.nanmean(dataset, axis = 0)\n",
      "print(average_ignoring_nan)\n",
      "# Columns with data type string with nan values\n",
      "string_columns = np.argwhere(np.isnan(average_ignoring_nan)).squeeze()\n",
      "string_columns\n",
      "np.isnan(average_ignoring_nan)\n",
      "# To see filter numerical columns\n",
      "numerical_columns = np.argwhere(np.isnan(average_ignoring_nan) == false).squeeze()\n",
      "numerical_columns\n",
      "# To see filter numerical columns\n",
      "numerical_columns = np.argwhere(np.isnan(average_ignoring_nan)) == false).squeeze()\n",
      "numerical_columns\n",
      "# To see filter numerical columns\n",
      "numerical_columns = np.argwhere(np.isnan(average_ignoring_nan) == false).squeeze()\n",
      "numerical_columns\n",
      "# To see filter numerical columns\n",
      "numerical_columns = np.argwhere(np.isnan(average_ignoring_nan) == False).squeeze()\n",
      "numerical_columns\n",
      "np.isnan(average_ignoring_nan) == False\n",
      "# We will loading only the columns with data type string\n",
      "arr_strings = np.genfromtxt(\"datasets/dataset1.csv\",\n",
      "                           delimiter = \";\",\n",
      "                           skip_header = 1,\n",
      "                           autostrip = True,\n",
      "                           usecols = string_columns,\n",
      "                           dtype = str,\n",
      "                           encoding = 'cp1252')\n",
      "arr_strings\n",
      "# We will loading only the columns with numerical data type \n",
      "# We specify the numerical columns with the index and their data type\n",
      "arr_numeric = np.genfromtxt(\"datasets/dataset1.csv\",\n",
      "                           delimiter = \";\",\n",
      "                           skip_header = 1,\n",
      "                           autostrip = True,\n",
      "                           usecols = numerical_columns,\n",
      "                           filling_values = joker_value,\n",
      "                           encoding = 'cp1252')\n",
      "arr_numeric\n",
      "# Loading the columns name\n",
      "arr_columns_name = np.genfromtxt(\"datasets/dataset1.csv\",\n",
      "                                delimiter = \";\",\n",
      "                                autostrip = True,\n",
      "                                skip_footer = dataset.shape[0],\n",
      "                                dtype = string,\n",
      "                                encoding = 'cp1252')\n",
      "# Loading the columns name\n",
      "arr_columns_name = np.genfromtxt(\"datasets/dataset1.csv\",\n",
      "                                delimiter = \";\",\n",
      "                                autostrip = True,\n",
      "                                skip_footer = dataset.shape[0],\n",
      "                                dtype = str,\n",
      "                                encoding = 'cp1252')\n",
      "arr_columns_name\n",
      "# Separate numerical and string column headers\n",
      "header_strings, header_numerical = arr_columns_name[string_columns], arr_columns_name[numerical_columns]\n",
      "header_strings\n",
      "header_numerical\n",
      "# We calculate the average of the numerical variables ignoring the nan values in the column\n",
      "# We will use this to separate numerical variables from string variables\n",
      "average_ignoring_nan = np.mean(dataset, axis = 0)\n",
      "print(average_ignoring_nan)\n",
      "# We calculate the average of the numerical variables ignoring the nan values in the column\n",
      "# We will use this to separate numerical variables from string variables\n",
      "average_ignoring_nan = np.nanmean(dataset, axis = 0)\n",
      "print(average_ignoring_nan)\n",
      "# Columns with data type string with nan values\n",
      "string_columns = np.argwhere(np.isnan(average_ignoring_nan))\n",
      "string_columns\n",
      "# Columns with data type string with nan values\n",
      "string_columns = np.argwhere(np.isnan(average_ignoring_nan)).squeeze()\n",
      "string_columns\n",
      "np.squeeze().help\n",
      "help.np.squeeze()\n",
      "]\n",
      "header_numerical\n",
      "header_strings\n",
      "header_numerical\n",
      "header_numerical\n",
      "header_numerical\n",
      "header_numerical\n",
      "header_strings\n",
      "header_strings\n",
      "header_strings\n",
      "header_numerical\n",
      "%who\n",
      "%who int\n",
      "%who str\n",
      "%who ndarray\n",
      "%lsmagic #show all magic commands\n",
      "%history\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f105525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bia/Code/GITHUB_DSA/DSA_Data-Science-Course/Big-Data-Real-Time-Analytics-with-Python-and-Spark/Data-Manipulation-with-Numpy'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c61c055c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Ch02-NumPy.ipynb  03-Ch02-NumPy.ipynb       \u001b[0m\u001b[01;34mdatasets\u001b[0m/\r\n",
      "02-Ch02-NumPy.ipynb  04-Ch02-CaseStudy1.ipynb  \u001b[01;34mimages\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc09a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Ch02-NumPy.ipynb  03-Ch02-NumPy.ipynb       \u001b[0m\u001b[01;34mdatasets\u001b[0m/\r\n",
      "02-Ch02-NumPy.ipynb  04-Ch02-CaseStudy1.ipynb  \u001b[01;34mimages\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf810c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 ms, sys: 0 ns, total: 44.8 ms\n",
      "Wall time: 44.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_to_run = [i**2 for i in range(0, 400000, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3864e7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f3f38f21640>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "x = np.random.rand(80)\n",
    "y = np.random.rand(80)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff33c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0560dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42100aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a1853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
