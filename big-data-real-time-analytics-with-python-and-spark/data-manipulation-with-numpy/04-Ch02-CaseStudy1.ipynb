{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ce2f19",
   "metadata": {},
   "source": [
    "# Big Data Real-Time Analytics with Python and Spark\n",
    "\n",
    "## Chapter 2  - Case Study 1 - Cleaning and processing data with Numpy\n",
    "\n",
    "- Documentation: https://numpy.org/\n",
    "- Data from: https://www.openintro.org/data/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735548d",
   "metadata": {},
   "source": [
    "![Case Study DSA](images/CaseStudy1.png \"Case Study DSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0e6b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version used in this notebook is:  3.8.8\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "from platform import python_version\n",
    "print('The version used in this notebook is: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a62d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the only library for the Python that we will use here \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7940c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca43be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Bianca Amorim\n",
      "\n",
      "numpy: 1.23.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# package version used in this notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Bianca Amorim\" --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939698d0",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54422aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print setting in Numpy\n",
    "np.set_printoptions(suppress = True, linewidth = 200, precision = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafdc64",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fd1dd",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data set \n",
    "dataset = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                        delimiter = \";\",\n",
    "                        skip_header = 1,\n",
    "                        autostrip = True,\n",
    "                        encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a438464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking type (ndarray is an array with many dimensions)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5517bebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 lines for 14 columns\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8e3b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab7da7",
   "metadata": {},
   "source": [
    "**\"nan\"** means \"not a number\". But we don't have empty columns. what happened was numpy did not recognize some data. This is because the special characters in the data set and the way NumPy loads numeric and string data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9a30a",
   "metadata": {},
   "source": [
    "## Verificando Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b45afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of total missing values\n",
    "# A good part of these missing values were generated at the time we loaded the data\n",
    "np.isnan(dataset).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a677f9",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.nanmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378e8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68616520.0\n"
     ]
    }
   ],
   "source": [
    "# It will return the highest value + 1, ignoring nan values\n",
    "# We will use this to fill in the nan values at the moment of the loading data numeric variables\n",
    "# then we will treat this value as a missing value\n",
    "joker_value = np.nanmax(dataset) + 1\n",
    "print(joker_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c922ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If I do not use this function above to ignore nan, the max values will be nan\n",
    "np.max(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577804b",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2394afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54015809.19         nan    15273.46         nan    15311.04         nan       16.62      440.92         nan         nan         nan         nan         nan     3143.85]\n"
     ]
    }
   ],
   "source": [
    "# We calculate the average of the numeric variables ignoring the nan values in the column\n",
    "# We will use this to separate numeric variables from string variables\n",
    "average_ignoring_nan = np.nanmean(dataset, axis = 0)\n",
    "print(average_ignoring_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9460163",
   "metadata": {},
   "source": [
    "- Return the position of the elements, that are non-zero\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98798815",
   "metadata": {},
   "source": [
    "- Squeeze the array, because we don't need [[0,1], [0, 3] ...\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f27dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with data type string with nan values\n",
    "# squeeze() We tranforming multiples arrays in one\n",
    "string_columns = np.argwhere(np.isnan(average_ignoring_nan)).squeeze()\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c7919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False,  True, False, False,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The function argwhere above return the position only if is true(1)\n",
    "# Because the false is a 0, and the function argwhere do not return position when the value is a 0\n",
    "np.isnan(average_ignoring_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60b2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see filter numericac columns\n",
    "numeric_columns = np.argwhere(np.isnan(average_ignoring_nan) == False).squeeze()\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe8a3625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True, False,  True,  True, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the columns which is true is the not nan\n",
    "np.isnan(average_ignoring_nan) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885f4b0",
   "metadata": {},
   "source": [
    "> Import the dataset again, separating string columns from numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d202b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will loading only the columns with string data type \n",
    "# We specify the string columns with the index and their data type\n",
    "arr_strings = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                           delimiter = \";\",\n",
    "                           skip_header = 1,\n",
    "                           autostrip = True,\n",
    "                           usecols = string_columns,\n",
    "                           dtype = str,\n",
    "                           encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f9053bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da9aabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will loading only the columns with numeric data type \n",
    "# We specify the numeric columns with the index and their data type\n",
    "# filling_values - set values to be used as default when the data are missing.\n",
    "arr_numeric = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                           delimiter = \";\",\n",
    "                           skip_header = 1,\n",
    "                           autostrip = True,\n",
    "                           usecols = numeric_columns,\n",
    "                           filling_values = joker_value,\n",
    "                           encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cbf45e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d37879",
   "metadata": {},
   "source": [
    "> Now we are going to extract the columns names, we didn't extract them before because they are all of type string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19fd6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the columns name\n",
    "arr_columns_name = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                                delimiter = \";\",\n",
    "                                autostrip = True,\n",
    "                                skip_footer = dataset.shape[0],\n",
    "                                dtype = str,\n",
    "                                encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78e508b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_columns_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd21b8",
   "metadata": {},
   "source": [
    "> \"skip_footer\" is the index of the lines to skip at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50cf8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and string column headers\n",
    "header_strings, header_numeric = arr_columns_name[string_columns], arr_columns_name[numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31d642fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd11f33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766f573",
   "metadata": {},
   "source": [
    "## Checkpoint function\n",
    "### Checkpoint 1\n",
    "We will create a checkpoint function to salve the intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ff33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A funtion that will save in disk, everything that we have until here.\n",
    "# I choose what I will save here.\n",
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header = checkpoint_header, data = checkpoint_data)\n",
    "    checkpoint_variable = np.load(file_name + \".npz\")\n",
    "    return(checkpoint_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db0560dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will save our strings arrays, because they are more critical\n",
    "checkpoint_inicial = checkpoint(\"datasets/Checkpoint-Inicial\", header_strings, arr_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e42100aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_inicial['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe4a1853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I ask if the array created is equal my strings array. Must to be equal.\n",
    "np.array_equal(checkpoint_inicial['data'], arr_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b23cc",
   "metadata": {},
   "source": [
    "## Manipulating strings columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bbe8254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ab48669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will with the first column\n",
    "# We will change the name to facilitate columns identification\n",
    "header_strings[0] = \"issue_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eb2fae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5e46a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba4b8b",
   "metadata": {},
   "source": [
    "## Preprocessing the variable issue_date with Label Encoding\n",
    "This is a preprocessing strategy to vategory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "172656a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15', 'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the unique values of this variable\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd19e75",
   "metadata": {},
   "source": [
    "- Notice that we always have the month and -15, because they extract the data on the 15th. We don't need this part, just the month and then we can apply the label encoding strategy. We can not deliver text for the ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ae71ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the strip to cut -15 in the string, and save in the same variable\n",
    "# Numpy is excelent! Do this with other tools is not so easy.\n",
    "arr_strings[:,0] = np.chararray.strip(arr_strings[:,0], \"-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53dcf4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'], dtype='<U69')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0c2a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that we have nan values, we have to consider this too\n",
    "# We will first create an array with the months\n",
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c1e4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to convert the name og the months to numeric numbers\n",
    "# We call this \"LABEL ENCONDING\"\n",
    "for i in range(13):\n",
    "    arr_strings[:,0] = np.where(arr_strings[:,0] == months[i], i, arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6ec20",
   "metadata": {},
   "source": [
    "The funtion above check if each is equal to some month in my months array. If is it equal, I will replace my month array i (index number) and if is not I will keep the value that I have in my strings array, always in the columns 0. \n",
    "This way I replace every month by number, and the nan by 0. This is a good statregy, because there is no 0 month. So I know this indicate a nan value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e46b775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c278d0e",
   "metadata": {},
   "source": [
    "## Preprocessing the variable loan_status with binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7de9a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "549fafec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued', 'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column loan_status\n",
    "np.unique(arr_strings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29540605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the number of the elements that we have\n",
    "np.unique(arr_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475e706",
   "metadata": {},
   "source": [
    "In this part of the process we have to know or ask what is important, because maybe is not necessary every information and you can categorize the data. Here, we only need to know if the loan status is good or not. So we will create a list to use as a reference when the status is bad.\n",
    "\n",
    "If the category is in the list status_bad we will put one value(0), if not, we put another one(1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "429ddee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the array with the bad status\n",
    "# we put the nan values too because we do not know what they are\n",
    "status_bad = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4693e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check if the values is in status_bad and convert the columns values to binary values\n",
    "arr_strings[:,1] = np.where(np.isin(arr_strings[:,1], status_bad),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf8a78f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column loan_status to confirm\n",
    "np.unique(arr_strings[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13ac2c",
   "metadata": {},
   "source": [
    "## Preprocessing the variable term with clean string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e937d6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d7f8506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See at the source of the data they do not worry about ML analyse\n",
    "# Here we can see that the data has numbers and strings\n",
    "np.unique(arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fab1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word months \n",
    "# Attention with the space, I have to remove now, because we need only number\n",
    "arr_strings[:,2] = np.chararray.strip(arr_strings[:,2], \" months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d1ee71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of the variable to know that the numbers in the columns is number\n",
    "header_strings[2] = \"term_months\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "166bf7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nan values is a problem, we do not have to keep it. We always have to process in some way.\n",
    "# we have to decide what to do with them\n",
    "arr_strings[:,2] = np.where(arr_strings[:,2] == '', '60', arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb9de0",
   "metadata": {},
   "source": [
    "- **Note:** If above I do not know how much time the person will pay, it is good to put the greater number available. It is no sense to put 0, because they will take some time always, and maybe its not the less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db194a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59d486fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623b6ab",
   "metadata": {},
   "source": [
    "## Preprocessing variables grade and subgrade with dictionary (A Label Encoding Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0edd6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59046e9b",
   "metadata": {},
   "source": [
    "**Note:** You as a analyst must to be attention in the name of the variables and what they are. In this example variables 'grade' and 'sub_grade' seems to be related each other. They have similar names, so you have to check if they represent similar informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fea1a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column grade\n",
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5584bf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1',\n",
       "       'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column sub_grade\n",
    "np.unique(arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34d3c5",
   "metadata": {},
   "source": [
    "**Note:** If variables represent the same level of information, there is no sense to keep both. That is not good in ML models because I will be reinforcing certain information.\n",
    "**_Keeping both variables is not a good decision._** it makes more sense to keep the variable sub_grade, which has more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c2c179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a0d1e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values of the valid categories (without nan)\n",
    "# Example of slice without nan number that you have to use below\n",
    "# With this we has all the values without errors, nan is an error\n",
    "np.unique(arr_strings[:,3])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46ff1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to set the variable sub_grade\n",
    "# I will go through each of the values without nan\n",
    "for i in np.unique(arr_strings[:,3])[1:]:\n",
    "    arr_strings[:,4] = np.where((arr_strings[:,4] == '') & (arr_strings[:,3] == i), i + '5', arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b6552",
   "metadata": {},
   "source": [
    "**I do that to make sure that the two variables are related in some way**.\n",
    "We can se above that for each category, in the columns grade, I go until the sub_grade and I do the firt check: if has nan values, I do the second check: if in the value of columns grade is equal i. If both conditions is true, I will replace the value in subgrade with the concatenation i + '5', if not, I keep what I already have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e86350f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1',\n",
       "        'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the value with the count of elements in each one\n",
    "np.unique(arr_strings[:,4], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd7772f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nan value continue because before I put both condition.\n",
    "# I need to treat the missing value\n",
    "# RepÄºace the nan value for H1 (I do not have H1 yet)\n",
    "arr_strings[:,4] = np.where(arr_strings[:,4] == '', 'H1', arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89b41e",
   "metadata": {},
   "source": [
    "Delete the grade columns because we do not need it anymore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee5cb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the grade column\n",
    "arr_strings = np.delete(arr_strings, 3, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a68c2",
   "metadata": {},
   "source": [
    "**Note:** When we delete a variable the columns ajust, now the 3 columns is subgrade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3bd49c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5172360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_strings = np.delete(header_strings, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c2e4e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub_grade'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the column name\n",
    "header_strings[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4bcf7",
   "metadata": {},
   "source": [
    "Now we have the subgrade column ready to convert into a numeric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0106fa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2',\n",
       "       'G3', 'G4', 'G5', 'H1'], dtype='<U69')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the variable unique values\n",
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04391a6",
   "metadata": {},
   "source": [
    "**Create a dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49027969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A1'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of keys\n",
    "# Put the category values as key\n",
    "keys = list(np.unique(arr_strings[:,3]))\n",
    "keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "759c214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of values\n",
    "values = list(range(1, np.unique(arr_strings[:,3]).shape[0] + 1))\n",
    "values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95eb79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the keys and values\n",
    "# We use zip to join keys and values and create the dictionary\n",
    "dict_sub_grade = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95d905cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H1': 36}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b087a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use this dictionary to replace the values in our array in the dataset\n",
    "# We replace each category with the corresponding number\n",
    "for i in np.unique(arr_strings[:,3]):\n",
    "    arr_strings[:,3] = np.where(arr_strings[:,3] == i, dict_sub_grade[i], arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f4674be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '4', '5', '6',\n",
       "       '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the unique values of the variable\n",
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8dfb4c",
   "metadata": {},
   "source": [
    "## Preprocessing variables status with binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1dff35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the variables names\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae62cb72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract variables unique values\n",
    "np.unique(arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae3560",
   "metadata": {},
   "source": [
    "It seems that the last two variables represent the same or not. Here we will consider that is the same and apply binarization. And we will conseder here that the nan values was not verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eed03f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enconding with binarization\n",
    "arr_strings[:,4] = np.where((arr_strings[:,4] == '') | (arr_strings[:,4] == 'Not Verified'), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd73eb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract unique values of the variable to confirm the change\n",
    "np.unique(arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f540f8",
   "metadata": {},
   "source": [
    "## Preprocessing variables url with ID extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5bb1ff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the variables names\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f83c8e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', ..., 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## View a sample of the data\n",
    "arr_strings[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8f3ba",
   "metadata": {},
   "source": [
    "View a sample of the data and try to detect a pattern. Above we can see that the id number is the only information that differs from one record to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7edf6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the ID in the end of each url\n",
    "np.chararray.strip(arr_strings[:,5], 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba59943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the url value with the ID value\n",
    "arr_strings[:,5] = np.chararray.strip(arr_strings[:,5], 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9dfe5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226, 57693261, 59432726, ..., 50415990, 46154151, 66055249], dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the type to int32, because now we have only numbers\n",
    "arr_strings[:,5].astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685ccdd",
   "metadata": {},
   "source": [
    "The analyst should always pay attention to the others variables. We can see the first column in the numeric dataset, seems to have the same value that we extracted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2c8806c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226, 57693261, 59432726, ..., 50415990, 46154151, 66055249], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's convert the first columns in the numeric dataset to int32, to be able to compare\n",
    "arr_numeric[:,0].astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4dee18d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare if two arrays are equal\n",
    "# We can see above that is the same, but its good to confirm\n",
    "np.array_equal(arr_numeric[:,0].astype(dtype = np.int32), arr_strings[:,5].astype(dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "93310fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It removes the variable that we created above\n",
    "# Since they are the same, we can remove one. We choose remove that one in the arr_strings\n",
    "arr_strings = np.delete(arr_strings, 5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "931c9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It removes the head of the variable\n",
    "header_strings = np.delete(header_strings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "853142d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the new variable in index 5 column\n",
    "arr_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1ef02c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the new list of columns names\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1dee9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ID column\n",
    "arr_numeric[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f659ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ID column header\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d72012",
   "metadata": {},
   "source": [
    "## Preprocessing variables url with ID extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9abe22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ccfa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the name of the variable\n",
    "header_strings[5] = 'state_address'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bd821",
   "metadata": {},
   "source": [
    "- numpy.unique(return_counts=True) - return_counts: If is True, also return the number of times each unique item appears in ar.\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.unique.html?highlight=return_counts\n",
    "- numpy.argsort - Returns the indices that would sort an array.\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.argsort.html?highlight=argsort#numpy.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2aac601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract names and counting\n",
    "# Two variables because will return two values, the unique value and the count of each one\n",
    "states_names, states_count = np.unique(arr_strings[:,5], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd9b1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the indices that would sort the array states_count\n",
    "# Using this variable as a index I will sort by states_count\n",
    "# The \"-\" is to sort by descending order\n",
    "states_count_sorted = np.argsort(-states_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e008989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ', 'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY', 'KS', 'OK',\n",
       "        'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK', 'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,  216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,   84,   83,\n",
       "          74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,   25,   24,   17,   16,   10]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the states names and the counts sorted by states counts\n",
    "# Print using as index the return sorted from the function np.argsort\n",
    "states_names[states_count_sorted], states_count[states_count_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed13d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values(nan) value with 0\n",
    "arr_strings[:,5] = np.where(arr_strings[:,5] == '', 0, arr_strings[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ffca6",
   "metadata": {},
   "source": [
    "Is it relevant to know the state of each person? Is there some kind of analysis being done per state? If the answer is not, it doen't make sense to keep each state, I can convert the variable to regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3eb09cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the status by region\n",
    "states_west = np.array(['WA', 'OR', 'CA', 'NV', 'ID', 'MT', 'WY', 'UT', 'CO', 'AZ', 'NM', 'HI', 'AK'])\n",
    "states_south = np.array(['TX', 'OK', 'AR', 'LA', 'MS', 'AL', 'TN', 'KY', 'FL', 'GA', 'SC', 'NC', 'VA', 'WV', 'MD', 'DE', 'DC'])\n",
    "states_midwest = np.array(['ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'IN', 'MI', 'OH'])\n",
    "states_east = np.array(['PA', 'NY', 'NJ', 'CT', 'MA', 'VT', 'NH', 'ME', 'RI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9fccf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each state with the region ID\n",
    "arr_strings[:,5] = np.where(np.isin(arr_strings[:,5], states_west), 1, arr_strings[:,5])\n",
    "arr_strings[:,5] = np.where(np.isin(arr_strings[:,5], states_south), 2, arr_strings[:,5])\n",
    "arr_strings[:,5] = np.where(np.isin(arr_strings[:,5], states_midwest), 3, arr_strings[:,5])\n",
    "arr_strings[:,5] = np.where(np.isin(arr_strings[:,5], states_east), 4, arr_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9082fda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U69')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract unique values\n",
    "np.unique(arr_strings[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5628e5f",
   "metadata": {},
   "source": [
    "**You can change the data, but can not change the information!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4882e",
   "metadata": {},
   "source": [
    "## Converting an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2b97f",
   "metadata": {},
   "source": [
    "Our string array is now an numeric array. Let's ajust the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10ff113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', '1'],\n",
       "       ['0', '1', '36', '5', '1', '4'],\n",
       "       ['9', '1', '36', '10', '1', '4'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', '1'],\n",
       "       ['4', '1', '36', '17', '1', '3'],\n",
       "       ['12', '1', '36', '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "712ef835",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_strings = arr_strings.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a46c985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89a61b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30870b5",
   "metadata": {},
   "source": [
    "## Chekpoint with the cleaned and preprocessed string data\n",
    "### Checkpoint 2\n",
    "Completed the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4569f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_strings = checkpoint(\"datasets/Checkpoint-Strings\", header_strings, arr_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83e4e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_strings[\"header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7623a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_strings[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88463306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare if my checkpoint save on disk is the same as what we have saved in the computer's memory\n",
    "np.array_equal(checkpoint_strings['data'], arr_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5dbbe",
   "metadata": {},
   "source": [
    "## Manipulating numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "150d7ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "arr_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3dbc5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of the columns\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3648abe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many nan values we have\n",
    "# We do not have a missing values because when we load the data, we replace it with an arbtitay value\n",
    "np.isnan(arr_numeric).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6615a8",
   "metadata": {},
   "source": [
    "The 0 above indicates that we do not have a lack of that, but we have a lack of information. The joker value is not valid information for the whole dataset. We put it in to be able to replace, treat and make adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bb8a3f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joker_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "476d536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. We can check if each column has been filled with a joker value\n",
    "np.isin(arr_numeric[:,0], joker_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ad7ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. # We can check if each column has been filled with a joker value\n",
    "# This second option is better to be in no doubt, because we can have True in that \"...\"\n",
    "np.isin(arr_numeric[:,0], joker_value).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb524a",
   "metadata": {},
   "source": [
    "Lets creat an array os statistics, specifically the minimum, maximum and average value for each variable. We will use this to handle with missing values. (which is filled with Joker value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e1a17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with the minimum, maximum and average for each variable\n",
    "# We had already created the average variable in the beginning\n",
    "arr_stats = np.array([np.nanmin(dataset, axis = 0), average_ignoring_nan, np.nanmax(dataset, axis = 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52f97949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  373332.           nan     1000.           nan     1000.           nan        6.         31.42         nan         nan         nan         nan         nan        0.  ]\n",
      " [54015809.19         nan    15273.46         nan    15311.04         nan       16.62      440.92         nan         nan         nan         nan         nan     3143.85]\n",
      " [68616519.           nan    35000.           nan    35000.           nan       28.99     1372.97         nan         nan         nan         nan         nan    41913.62]]\n"
     ]
    }
   ],
   "source": [
    "print(arr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ea5514e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_stats[:, numeric_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58786193",
   "metadata": {},
   "source": [
    "## Preprocessing the variable funded_amnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dec767b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "arr_numeric[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c30fcc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_stats[0, numeric_columns[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "efff320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ajust the column content\n",
    "arr_numeric[:,2] = np.where(arr_numeric[:,2] == joker_value, arr_stats[0, numeric_columns[2]], arr_numeric[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "861aafe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438ee6e",
   "metadata": {},
   "source": [
    "## Preprocessing variables loan_amnt, int_rate, installment and total_pymnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4cf94533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of the columns\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "438dacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to replace nan values (joker value) with the values from statistic array\n",
    "for i in [1, 3, 4, 5]:\n",
    "    arr_numeric[:,i] = np.where(arr_numeric[:,i] == joker_value,\n",
    "                               arr_stats[2, numeric_columns[i]],\n",
    "                               arr_numeric[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c7691d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048dcbcb",
   "metadata": {},
   "source": [
    "## Working with the Second Dataset\n",
    "We will load the exchange rate USD - EURO. Each row of the dataset corresponds to the exchange rate for one month and one year. We have to do this because in this case we assume that the company will also need to see the currency in Euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a022a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second dataset\n",
    "# We need only the third column\n",
    "exchange_rate_data = np.genfromtxt(\"datasets/dataset2.csv\",\n",
    "                             delimiter = ',',\n",
    "                             autostrip = True,\n",
    "                             skip_header = 1,\n",
    "                             usecols = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cbaedaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13, 1.12, 1.08, 1.11, 1.1 , 1.12, 1.09, 1.13, 1.13, 1.1 , 1.06, 1.09])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "exchange_rate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "df0535d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Header names of strings data\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "86c40d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string data\n",
    "arr_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4729d9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  9, ...,  6,  4, 12])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 0 column in the string array is the month\n",
    "arr_strings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "13bcaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assign the month column to the variable called exchange_rate\n",
    "exchange_rate = arr_strings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9a50d66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  9, ...,  6,  4, 12])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5da60b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to fill the exchange variable with the rate corresponding to the month\n",
    "# We use exchange_rate_data[i -1] because the we took off the header when we load exchange_rate\n",
    "for i in range(1, 13):\n",
    "    exchange_rate = np.where(exchange_rate == i, exchange_rate_data[i - 1], exchange_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4dd7d7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 0.  , 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "30817f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the month 0 (nan values) with the average of the exchange rate \n",
    "exchange_rate = np.where(exchange_rate == 0, np.mean(exchange_rate_data), exchange_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "840278cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b1f6dfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape has to be the same of the numerical array\n",
    "# Compare both\n",
    "exchange_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6aa8d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c98d4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reshape to convert to an array format so we can then do the concatenation\n",
    "exchange_rate = np.reshape(exchange_rate, (10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0dca55a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a641d3",
   "metadata": {},
   "source": [
    "- numpy.**h**stack - stack arrays in sequence horizontally (column wise).\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.hstack.html?highlight=hstack#numpy.hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e5108a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal concatenation of arrays \n",
    "# To do this both arrays has to be the same shape\n",
    "arr_numeric = np.hstack((arr_numeric, exchange_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36b274f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the column name in the column name array\n",
    "header_numeric = np.concatenate((header_numeric, np.array(['exchange_rate'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3721d755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'], dtype='<U19')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51dc8b1",
   "metadata": {},
   "source": [
    "Let's create USD and EURO exchange rate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2b677576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the columns that are in dollar\n",
    "columns_dollar = np.array([1,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5162c7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exchange rate\n",
    "arr_numeric[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ed63b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "arr_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c6b35030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to create and add the 4 euro columns from the 4 dollar columns\n",
    "# See that we use reshape to create another column\n",
    "for i in columns_dollar:\n",
    "    arr_numeric = np.hstack((arr_numeric, np.reshape(arr_numeric[:,i] / arr_numeric[:,6], (10000,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bf8c7e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "arr_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a893d0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,    31933.3 ,     1081.04,     8624.69],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,    27132.46,      848.86,     4232.39],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,    13326.3 ,      439.64,     1750.04],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     8910.3 ,     1223.36,     1947.47],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,     8997.4 ,      318.78,     2878.63],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,     9145.8 ,      283.49,      276.11]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View\n",
    "arr_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0a752128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajust the column names\n",
    "header_additional = np.array([column_name + '_EUR' for column_name in header_numeric[columns_dollar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "438c2de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U15')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e171e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric = np.concatenate((header_numeric, header_additional))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "00f658df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate', 'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U19')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dbaba5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric[columns_dollar] = np.array([column_name + '_USD' for  column_name in header_numeric[columns_dollar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "61864cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'funded_amnt_USD', 'int_rate', 'installment_USD', 'total_pymnt_USD', 'exchange_rate', 'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "960e60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_index_order = [0, 1, 7, 2, 8, 3, 4, 9, 5, 10, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0d0c0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric = header_numeric[columns_index_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d4f37e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  , ...,    31933.3 ,     1081.04,     8624.69],\n",
       "       [57693261.  ,    30000.  ,    30000.  , ...,    27132.46,      848.86,     4232.39],\n",
       "       [59432726.  ,    15000.  ,    15000.  , ...,    13326.3 ,      439.64,     1750.04],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , ...,     8910.3 ,     1223.36,     1947.47],\n",
       "       [46154151.  ,    35000.  ,    10000.  , ...,     8997.4 ,      318.78,     2878.63],\n",
       "       [66055249.  ,    10000.  ,    10000.  , ...,     9145.8 ,      283.49,      276.11]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ed509a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_numeric = arr_numeric[:, columns_index_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cb476",
   "metadata": {},
   "source": [
    "## Preprocessing variable int_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fc5a2f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate', 'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b39ddd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.33, 28.99, 28.99, ..., 28.99, 16.55, 28.99])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "67fec1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by 100 to connvert the value to a fraction\n",
    "arr_numeric[:,5] =  arr_numeric[:,5] / 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "89413a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.29, 0.29, ..., 0.29, 0.17, 0.29])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a140a44",
   "metadata": {},
   "source": [
    "## Chekpoint with the cleaned and preprocessed numeric data\n",
    "### Checkpoint 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d5bc381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_numeric = checkpoint(\"datasets/Checkpoint-Numeric\", header_numeric, arr_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6e92fe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate', 'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "       dtype='<U19'),\n",
       " array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "        [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "        [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "        [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "        [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_numeric['header'], checkpoint_numeric['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e5d7d",
   "metadata": {},
   "source": [
    "## Building the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7216211c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of rows has to be the same in the both datasets, because we do not change it\n",
    "checkpoint_strings['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "27ce26b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_numeric['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bd6ae50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "df_final = np.hstack((checkpoint_numeric['data'], checkpoint_strings['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8016fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5353a9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there any missing value (nan), after all this work.\n",
    "np.isnan(df_final).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "593e73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate number of the columns\n",
    "header_full = np.concatenate((checkpoint_numeric['header'], checkpoint_strings['header']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e29916a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_USD', 'loan_amnt_EUR', 'funded_amnt_USD', 'funded_amnt_EUR', 'int_rate', 'installment_USD', 'installment_EUR', 'total_pymnt_USD', 'total_pymnt_EUR', 'exchange_rate',\n",
       "       'issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f087c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the final dataset by the Id Column (index :,0)\n",
    "df_final = df_final[np.argsort(df_final[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "80eb05ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     9950.  ,     9038.08, ...,       21.  ,        0.  ,        1.  ],\n",
       "       [  575239.  ,    12000.  ,    10900.2 , ...,       25.  ,        1.  ,        2.  ],\n",
       "       [  707689.  ,    10000.  ,     8924.3 , ...,       13.  ,        1.  ,        0.  ],\n",
       "       ...,\n",
       "       [68614880.  ,     5600.  ,     5121.65, ...,        8.  ,        1.  ,        1.  ],\n",
       "       [68615915.  ,     4000.  ,     3658.32, ...,       10.  ,        1.  ,        2.  ],\n",
       "       [68616519.  ,    21600.  ,    19754.93, ...,        3.  ,        0.  ,        2.  ]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "57154948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the sort in the column ID\n",
    "np.argsort(df_final[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475492e",
   "metadata": {},
   "source": [
    "## Save the Final Dataset Cleaned and Preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddf86f",
   "metadata": {},
   "source": [
    "- numpy.**v**stack - Stack arrays in sequence vertically (row wise).\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.vstack.html?highlight=vstack#numpy.vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9fd56d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = np.vstack((header_full, df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dd93179f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_amnt_USD', 'loan_amnt_EUR', ..., 'sub_grade', 'verification_status', 'state_address'],\n",
       "       ['373332.0', '9950.0', '9038.082814338286', ..., '21.0', '0.0', '1.0'],\n",
       "       ['575239.0', '12000.0', '10900.20037910145', ..., '25.0', '1.0', '2.0'],\n",
       "       ...,\n",
       "       ['68614880.0', '5600.0', '5121.647851612413', ..., '8.0', '1.0', '1.0'],\n",
       "       ['68615915.0', '4000.0', '3658.319894008867', ..., '10.0', '1.0', '2.0'],\n",
       "       ['68616519.0', '21600.0', '19754.927427647883', ..., '3.0', '0.0', '2.0']], dtype='<U32')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "62682f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in Disk\n",
    "np.savetxt(\"datasets/cleaned_preprocessed_dataset.csv\",\n",
    "          df_final,\n",
    "          fmt = '%s',\n",
    "          delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f5a8f",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
