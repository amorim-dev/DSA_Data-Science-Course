{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ce2f19",
   "metadata": {},
   "source": [
    "# Big Data Real-Time Analytics with Python and Spark\n",
    "\n",
    "## Chapter 2  - Case Study 1 - Cleaning and processing data with Numpy\n",
    "\n",
    "- Documentation: https://numpy.org/\n",
    "- Data from: https://www.openintro.org/data/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735548d",
   "metadata": {},
   "source": [
    "![Case Study DSA](images/CaseStudy1.png \"Case Study DSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0e6b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version used in this notebook is:  3.8.8\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "from platform import python_version\n",
    "print('The version used in this notebook is: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a62d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the only library for the Python that we will use here \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7940c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca43be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Bianca Amorim\n",
      "\n",
      "numpy: 1.21.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# package version used in this notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Bianca Amorim\" --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939698d0",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54422aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print setting in Numpy\n",
    "np.set_printoptions(suppress = True, linewidth = 200, precision = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafdc64",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fd1dd",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data set \n",
    "dataset = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                        delimiter = \";\",\n",
    "                        skip_header = 1,\n",
    "                        autostrip = True,\n",
    "                        encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a438464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking type (ndarray is an array with many dimensions)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5517bebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 lines for 14 columns\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8e3b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab7da7",
   "metadata": {},
   "source": [
    "**\"nan\"** means \"not a number\". But we don't have empty columns. what happened was numpy did not recognize some data. This is because the special characters in the data set and the way NumPy loads numerical and string data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9a30a",
   "metadata": {},
   "source": [
    "## Verificando Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b45afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of total missing values\n",
    "# A good part of these missing values were generated at the time we loaded the data\n",
    "np.isnan(dataset).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a677f9",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.nanmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378e8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68616520.0\n"
     ]
    }
   ],
   "source": [
    "# It will return the highest value + 1, ignoring nan values\n",
    "# We will use this to fill in the nan values at the moment of the loading data numerical variables\n",
    "# then we will treat this value as a missing value\n",
    "joker_value = np.nanmax(dataset) + 1\n",
    "print(joker_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c922ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If I do not use this function above to ignore nan, the max values will be nan\n",
    "np.max(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577804b",
   "metadata": {},
   "source": [
    "- https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2394afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54015809.19         nan    15273.46         nan    15311.04         nan       16.62      440.92         nan         nan         nan         nan         nan     3143.85]\n"
     ]
    }
   ],
   "source": [
    "# We calculate the average of the numerical variables ignoring the nan values in the column\n",
    "# We will use this to separate numerical variables from string variables\n",
    "average_ignoring_nan = np.nanmean(dataset, axis = 0)\n",
    "print(average_ignoring_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9460163",
   "metadata": {},
   "source": [
    "- Return the position of the elements, that are non-zero\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98798815",
   "metadata": {},
   "source": [
    "- Squeeze the array, because we don't need [[0,1], [0, 3] ...\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f27dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with data type string with nan values\n",
    "# squeeze() We tranforming multiples arrays in one\n",
    "string_columns = np.argwhere(np.isnan(average_ignoring_nan)).squeeze()\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c7919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False,  True, False, False,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The function argwhere above return the position only if is true(1)\n",
    "# Because the false is a 0, and the function argwhere do not return position when the value is a 0\n",
    "np.isnan(average_ignoring_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60b2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see filter numerical columns\n",
    "numerical_columns = np.argwhere(np.isnan(average_ignoring_nan) == False).squeeze()\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe8a3625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True, False,  True,  True, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the columns which is true is the not nan\n",
    "np.isnan(average_ignoring_nan) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885f4b0",
   "metadata": {},
   "source": [
    "> Import the dataset again, separating string columns from numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d202b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will loading only the columns with string data type \n",
    "# We specify the string columns with the index and their data type\n",
    "arr_strings = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                           delimiter = \";\",\n",
    "                           skip_header = 1,\n",
    "                           autostrip = True,\n",
    "                           usecols = string_columns,\n",
    "                           dtype = str,\n",
    "                           encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f9053bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da9aabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will loading only the columns with numerical data type \n",
    "# We specify the numerical columns with the index and their data type\n",
    "# filling_values - set values to be used as default when the data are missing.\n",
    "arr_numeric = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                           delimiter = \";\",\n",
    "                           skip_header = 1,\n",
    "                           autostrip = True,\n",
    "                           usecols = numerical_columns,\n",
    "                           filling_values = joker_value,\n",
    "                           encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cbf45e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d37879",
   "metadata": {},
   "source": [
    "> Now we are going to extract the columns names, we didn't extract them before because they are all of type string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19fd6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the columns name\n",
    "arr_columns_name = np.genfromtxt(\"datasets/dataset1.csv\",\n",
    "                                delimiter = \";\",\n",
    "                                autostrip = True,\n",
    "                                skip_footer = dataset.shape[0],\n",
    "                                dtype = str,\n",
    "                                encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78e508b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_columns_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd21b8",
   "metadata": {},
   "source": [
    "> \"skip_footer\" is the index of the lines to skip at the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50cf8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and string column headers\n",
    "header_strings, header_numerical = arr_columns_name[string_columns], arr_columns_name[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31d642fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd11f33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766f573",
   "metadata": {},
   "source": [
    "## Checkpoint function\n",
    "#### Checkpoint 1\n",
    "We will create a checkpoint function to salve the intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ff33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A funtion that will save in disk, everything that we have until here.\n",
    "# I choose what I will save here.\n",
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header = checkpoint_header, data = checkpoint_data)\n",
    "    checkpoint_variable = np.load(file_name + \".npz\")\n",
    "    return(checkpoint_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db0560dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will save our strings arrays, because they are more critical\n",
    "checkpoint_inicial = checkpoint(\"datasets/Checkpoint-Inicial\", header_strings, arr_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e42100aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_inicial['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe4a1853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I ask if the array created is equal my strings array. Must to be equal.\n",
    "np.array_equal(checkpoint_inicial['data'], arr_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b23cc",
   "metadata": {},
   "source": [
    "## Manipulating strings columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bbe8254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ab48669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will with the first column\n",
    "# We will change the name to facilitate columns identification\n",
    "header_strings[0] = \"issue_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eb2fae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5e46a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba4b8b",
   "metadata": {},
   "source": [
    "## Preprocessing the variable issue_date with Label Encoding\n",
    "This is a preprocessing strategy to vategory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "172656a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15', 'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the unique values of this variable\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd19e75",
   "metadata": {},
   "source": [
    "- Notice that we always have the month and -15, because they extract the data on the 15th. We don't need this part, just the month and then we can apply the label encoding strategy. We can not deliver text for the ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ae71ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the strip to cut -15 in the string, and save in the same variable\n",
    "# Numpy is excelent! Do this with other tools is not so easy.\n",
    "arr_strings[:,0] = np.chararray.strip(arr_strings[:,0], \"-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53dcf4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'], dtype='<U69')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0c2a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that we have nan values, we have to consider this too\n",
    "# We will first create an array with the months\n",
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c1e4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to convert the name og the months to numerical numbers\n",
    "# We call this \"LABEL ENCONDING\"\n",
    "for i in range(13):\n",
    "    arr_strings[:,0] = np.where(arr_strings[:,0] == months[i], i, arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6ec20",
   "metadata": {},
   "source": [
    "The funtion above check if each is equal to some month in my months array. If is it equal, I will replace my month array i (index number) and if is not I will keep the value that I have in my strings array, always in the columns 0. \n",
    "This way I replace every month by number, and the nan by 0. This is a good statregy, because there is no 0 month. So I know this indicate a nan value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e46b775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c278d0e",
   "metadata": {},
   "source": [
    "## Preprocessing the variable loan_status with binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7de9a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "549fafec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued', 'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column loan_status\n",
    "np.unique(arr_strings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29540605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the number of the elements that we have\n",
    "np.unique(arr_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475e706",
   "metadata": {},
   "source": [
    "In this part of the process we have to know or ask what is important, because maybe is not necessary every information and you can categorize the data. Here, we only need to know if the loan status is good or not. So we will create a list to use as a reference when the status is bad.\n",
    "\n",
    "If the category is in the list status_bad we will put one value(0), if not, we put another one(1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "429ddee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the array with the bad status\n",
    "# we put the nan values too because we do not know what they are\n",
    "status_bad = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4693e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check if the values is in status_bad and convert the columns values to binary values\n",
    "arr_strings[:,1] = np.where(np.isin(arr_strings[:,1], status_bad),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf8a78f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column loan_status to confirm\n",
    "np.unique(arr_strings[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13ac2c",
   "metadata": {},
   "source": [
    "## Preprocessing the variable term with clean string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e937d6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d7f8506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See at the source of the data they do not worry about ML analyse\n",
    "# Here we can see that the data has numbers and strings\n",
    "np.unique(arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fab1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word months \n",
    "# Attention with the space, I have to remove now, because we need only number\n",
    "arr_strings[:,2] = np.chararray.strip(arr_strings[:,2], \" months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d1ee71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of the variable to know that the numbers in the columns is number\n",
    "header_strings[2] = \"term_months\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "166bf7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nan values is a problem, we do not have to keep it. We always have to process in some way.\n",
    "# we have to decide what to do with them\n",
    "arr_strings[:,2] = np.where(arr_strings[:,2] == '', '60', arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb9de0",
   "metadata": {},
   "source": [
    "- **Note:** If above I do not know how much time the person will pay, it is good to put the greater number available. It is no sense to put 0, because they will take some time always, and maybe its not the less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db194a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59d486fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623b6ab",
   "metadata": {},
   "source": [
    "## Preprocessing variables grade and subgrade with dictionary (A Label Encoding Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0edd6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59046e9b",
   "metadata": {},
   "source": [
    "**Note:** You as a analyst must to be attention in the name of the variables and what they are. In this example variables 'grade' and 'sub_grade' seems to be related each other. They have similar names, so you have to check if they represent similar informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fea1a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column grade\n",
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5584bf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1',\n",
       "       'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estract the unique values from the column sub_grade\n",
    "np.unique(arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34d3c5",
   "metadata": {},
   "source": [
    "**Note:** If variables represent the same level of information, there is no sense to keep both. That is not good in ML models because I will be reinforcing certain information.\n",
    "**_Keeping both variables is not a good decision._** it makes more sense to keep the variable sub_grade, which has more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c2c179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a0d1e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values of the valid categories (without nan)\n",
    "# Example of slice without nan number that you have to use below\n",
    "# With this we has all the values without errors, nan is an error\n",
    "np.unique(arr_strings[:,3])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46ff1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to set the variable sub_grade\n",
    "# I will go through each of the values without nan\n",
    "for i in np.unique(arr_strings[:,3])[1:]:\n",
    "    arr_strings[:,4] = np.where((arr_strings[:,4] == '') & (arr_strings[:,3] == i), i + '5', arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b6552",
   "metadata": {},
   "source": [
    "**I do that to make sure that the two variables are related in some way**.\n",
    "We can se above that for each category, in the columns grade, I go until the sub_grade and I do the firt check: if has nan values, I do the second check: if in the value of columns grade is equal i. If both conditions is true, I will replace the value in subgrade with the concatenation i + '5', if not, I keep what I already have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e86350f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1',\n",
       "        'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the value with the count of elements in each one\n",
    "np.unique(arr_strings[:,4], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd7772f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nan value continue because before I put both condition.\n",
    "# I need to treat the missing value\n",
    "# Repĺace the nan value for H1 (I do not have H1 yet)\n",
    "arr_strings[:,4] = np.where(arr_strings[:,4] == '', 'H1', arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5e0c3",
   "metadata": {},
   "source": [
    "Delete the grade columns because we do not need it anymore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "884382fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the grade column\n",
    "arr_strings = np.delete(arr_strings, 3, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a1400",
   "metadata": {},
   "source": [
    "**Note:** When we delete a variable the columns ajust, now the 3 columns is subgrade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97bf9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_strings[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9081045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
